{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After I scraped Politico, it turned out their individual political parties were rife with error. So I scraped them from the New York Times and merged them back. As an added bonus, NYT had a bunch of races like state legislatures that Politico didn't have. As another bonus, all the data for New York Times election results is hardcoded as a Javascript object in the page source!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first use Selenium to get a dict of urls for state results.\n",
    "if not os.path.isfile('nyt_state2url.json'):\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.support.ui import Select\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.get(\"http://www.nytimes.com/elections/results/alabama\")\n",
    "    # click on 'State Results' item to get list of states and URLs\n",
    "    toexpand = driver.find_element_by_xpath('//*[@id=\"shell\"]/nav/div/a[6]')\n",
    "    toexpand.click()\n",
    "    outerhtml = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "    soup = BeautifulSoup(outerhtml, 'lxml')\n",
    "    nav = soup.find_all('nav', attrs={'class': \"eln-navigation-states\"})[0]\n",
    "    state2url = {}\n",
    "    for tag in nav.find_all('a'):\n",
    "        state2url[tag.attrs['title']] = tag.attrs['href']\n",
    "    driver.quit()\n",
    "    with open('nyt_state2url.json', 'w+') as f:\n",
    "        f.write(json.dumps(state2url))\n",
    "else:\n",
    "    with open('nyt_state2url.json', 'r') as f:\n",
    "        state2url = json.load(f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nytresults = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missouri\n",
      "South Dakota\n",
      "Ohio\n",
      "Colorado\n",
      "Nevada\n",
      "North Carolina\n",
      "Texas\n",
      "Virginia\n",
      "Florida\n",
      "Arkansas\n",
      "New Mexico\n",
      "District of Columbia\n",
      "Tennessee\n",
      "Oklahoma\n",
      "North Dakota\n",
      "Wyoming\n",
      "Iowa\n",
      "New Jersey\n",
      "Minnesota\n",
      "Rhode Island\n",
      "Delaware\n",
      "Wisconsin\n",
      "Mississippi\n",
      "Michigan\n",
      "Indiana\n",
      "Alaska\n",
      "California\n",
      "Massachusetts\n",
      "New Hampshire\n",
      "Connecticut\n",
      "Louisiana\n",
      "West Virginia\n",
      "Georgia\n",
      "Maine\n",
      "Illinois\n",
      "Kansas\n",
      "Arizona\n",
      "New York\n",
      "South Carolina\n",
      "Idaho\n",
      "Pennsylvania\n",
      "Montana\n",
      "Kentucky\n",
      "Alabama\n",
      "Utah\n",
      "Vermont\n",
      "Nebraska\n",
      "Oregon\n",
      "Maryland\n",
      "Hawaii\n",
      "Washington\n"
     ]
    }
   ],
   "source": [
    "for state, url in state2url.items():\n",
    "    print(state)\n",
    "    r = requests.get(url)\n",
    "    assert r.status_code == 200\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    for script in soup.find_all('script'):\n",
    "        if script.text.find('eln_election_date') != -1:\n",
    "            break\n",
    "    for line in script.text.split('\\n'):\n",
    "        if line.find('eln_races = [{\"') != -1:\n",
    "            break\n",
    "    blob = re.search(\"eln_races\\s+=\\s+(.+),\", line).group(1)\n",
    "    blob = re.sub('<a href=\"(.+?)\">', r'a href=\\\"\\1\\\">', blob) # escape the double quotes inside a url inside json\n",
    "    nytresults[state] = json.loads(blob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('nyt_election_2016_by_state.json', 'w+') as f:\n",
    "    f.write(json.dumps(nytresults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py34]",
   "language": "python",
   "name": "Python [py34]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
